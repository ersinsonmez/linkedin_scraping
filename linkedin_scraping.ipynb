{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb23fb1b",
   "metadata": {},
   "source": [
    "# LinkedIn Scraping\n",
    "\n",
    "Note: Before running this script, please execute \"chromedriver_win32.zip\" and don't forget to install the necessary packages with \"pip install\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21031909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finished: importing package\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "\n",
    "print('- Finished: importing package')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944d9dd0",
   "metadata": {},
   "source": [
    "## Step 1: Login to Linkedin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bdfd72",
   "metadata": {},
   "source": [
    "### Open Chrome and Login Linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1c0d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finished: initializing a driver\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "url = \"https://www.linkedin.com/login\"\n",
    "driver.get(url)\n",
    "print('- Finished: initializing a driver')\n",
    "sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7795dbf",
   "metadata": {},
   "source": [
    "### Login Info (read from file)\n",
    "Mail and password are read from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da183c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finished: importing the login credentials\n"
     ]
    }
   ],
   "source": [
    "credential = open('login_info.txt')\n",
    "line = credential.readlines()\n",
    "username = line[0]\n",
    "password = line[1]\n",
    "print('- Finished: importing the login credentials')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8172069e",
   "metadata": {},
   "source": [
    "### Key in username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa4598ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finished: keying in email\n"
     ]
    }
   ],
   "source": [
    "email_field = driver.find_element('id','username')\n",
    "email_field.send_keys(username)\n",
    "print('- Finished: keying in email')\n",
    "sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120733c0",
   "metadata": {},
   "source": [
    "### Key in password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15cf9e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finished: keying in password\n"
     ]
    }
   ],
   "source": [
    "password_field = driver.find_element('name','session_password')\n",
    "password_field.send_keys(password)\n",
    "print('- Finished: keying in password')\n",
    "sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95140b8",
   "metadata": {},
   "source": [
    "### Click login button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4305043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finished: logging in\n"
     ]
    }
   ],
   "source": [
    "login_field = driver.find_element('xpath','//*[@id=\"organic-div\"]/form/div[3]/button')\n",
    "login_field.click()\n",
    "print('- Finished: logging in')\n",
    "sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8689c718",
   "metadata": {},
   "source": [
    "## Step 2: Create Query for Search URL and Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d37b8a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finished: requested search results\n"
     ]
    }
   ],
   "source": [
    "search_url = \"https://www.linkedin.com/search/results/people/?currentCompany=%5B%223894%22%2C%222734%22%2C%221384%22%2C%2210316337%22%2C%2211695727%22%2C%2211713%22%2C%221319%22%2C%221412%22%2C%2215564%22%2C%2217949565%22%2C%221882%22%2C%221904%22%2C%221951%22%2C%222426%22%2C%222723%22%2C%222810%22%2C%222914824%22%2C%2230846%22%2C%2231272%22%2C%2240745219%22%2C%226469%22%2C%228693%22%5D&origin=FACETED_SEARCH&pastCompany=%5B%225199486%22%2C%225434756%22%2C%22643103%22%2C%22164632%22%2C%2210687132%22%2C%226403807%22%2C%221625582%22%2C%221424395%22%2C%2254090987%22%2C%2210042%22%2C%221003487%22%2C%2210098489%22%2C%2210682967%22%2C%2211376152%22%2C%22120487%22%2C%2212381%22%2C%2214900%22%2C%22166295%22%2C%2217774325%22%2C%2218280993%22%2C%22224745%22%2C%222404635%22%2C%222488212%22%2C%2228165697%22%2C%22359807%22%2C%2252180235%22%2C%22638722%22%2C%22770320%22%2C%2282111984%22%2C%228739702%22%2C%228970%22%2C%22941212%22%2C%229612%22%5D&sid=~-H\"\n",
    "driver.get(search_url)\n",
    "print('- Finished: requested search results')\n",
    "sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b7caff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = BeautifulSoup(driver.page_source, \"html.parser\") # get html source code for page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd18a80",
   "metadata": {},
   "source": [
    "### Print the number of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dccd8824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finished: search result: 888 sonuÃ§\n"
     ]
    }
   ],
   "source": [
    "result_number=page_source.find(class_='pb2 t-black--light t-14').text.replace(\"\\n\",\"\").removeprefix(\" \")\n",
    "print('- Finished: search result: {}'.format(result_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d772da53",
   "metadata": {},
   "source": [
    "## Step 3: Scrape the URL's of the profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed1db2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetURL():\n",
    "    \n",
    "    profiles = page_source.findChildren('span',class_='entity-result__title-text')\n",
    "    all_URLs = []\n",
    "\n",
    "    for profile in profiles:\n",
    "         profile_URL = profile.find('a').get('href')\n",
    "         all_URLs.append(profile_URL)\n",
    "         \n",
    "    return all_URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04280d86",
   "metadata": {},
   "source": [
    "## Step 4: Next Page algorithm and storing URL's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e43ddc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many pages should we scraped?: 89\n",
      "- Finished: Page - 1 --> scraped\n",
      "- Finished: Page - 2 --> scraped\n",
      "- Finished: Page - 3 --> scraped\n",
      "- Finished: Page - 4 --> scraped\n",
      "- Finished: Page - 5 --> scraped\n",
      "- Finished: Page - 6 --> scraped\n",
      "- Finished: Page - 7 --> scraped\n",
      "- Finished: Page - 8 --> scraped\n",
      "- Finished: Page - 9 --> scraped\n",
      "- Finished: Page - 10 --> scraped\n",
      "- Finished: Page - 11 --> scraped\n",
      "- Finished: Page - 12 --> scraped\n",
      "- Finished: Page - 13 --> scraped\n",
      "- Finished: Page - 14 --> scraped\n",
      "- Finished: Page - 15 --> scraped\n",
      "- Finished: Page - 16 --> scraped\n",
      "- Finished: Page - 17 --> scraped\n",
      "- Finished: Page - 18 --> scraped\n",
      "- Finished: Page - 19 --> scraped\n",
      "- Finished: Page - 20 --> scraped\n",
      "- Finished: Page - 21 --> scraped\n",
      "- Finished: Page - 22 --> scraped\n",
      "- Finished: Page - 23 --> scraped\n",
      "- Finished: Page - 24 --> scraped\n",
      "- Finished: Page - 25 --> scraped\n",
      "- Finished: Page - 26 --> scraped\n",
      "- Finished: Page - 27 --> scraped\n",
      "- Finished: Page - 28 --> scraped\n",
      "- Finished: Page - 29 --> scraped\n",
      "- Finished: Page - 30 --> scraped\n",
      "- Finished: Page - 31 --> scraped\n",
      "- Finished: Page - 32 --> scraped\n",
      "- Finished: Page - 33 --> scraped\n",
      "- Finished: Page - 34 --> scraped\n",
      "- Finished: Page - 35 --> scraped\n",
      "- Finished: Page - 36 --> scraped\n",
      "- Finished: Page - 37 --> scraped\n",
      "- Finished: Page - 38 --> scraped\n",
      "- Finished: Page - 39 --> scraped\n",
      "- Finished: Page - 40 --> scraped\n",
      "- Finished: Page - 41 --> scraped\n",
      "- Finished: Page - 42 --> scraped\n",
      "- Finished: Page - 43 --> scraped\n",
      "- Finished: Page - 44 --> scraped\n",
      "- Finished: Page - 45 --> scraped\n",
      "- Finished: Page - 46 --> scraped\n",
      "- Finished: Page - 47 --> scraped\n",
      "- Finished: Page - 48 --> scraped\n",
      "- Finished: Page - 49 --> scraped\n",
      "- Finished: Page - 50 --> scraped\n",
      "- Finished: Page - 51 --> scraped\n",
      "- Finished: Page - 52 --> scraped\n",
      "- Finished: Page - 53 --> scraped\n",
      "- Finished: Page - 54 --> scraped\n",
      "- Finished: Page - 55 --> scraped\n",
      "- Finished: Page - 56 --> scraped\n",
      "- Finished: Page - 57 --> scraped\n",
      "- Finished: Page - 58 --> scraped\n",
      "- Finished: Page - 59 --> scraped\n",
      "- Finished: Page - 60 --> scraped\n",
      "- Finished: Page - 61 --> scraped\n",
      "- Finished: Page - 62 --> scraped\n",
      "- Finished: Page - 63 --> scraped\n",
      "- Finished: Page - 64 --> scraped\n",
      "- Finished: Page - 65 --> scraped\n",
      "- Finished: Page - 66 --> scraped\n",
      "- Finished: Page - 67 --> scraped\n",
      "- Finished: Page - 68 --> scraped\n",
      "- Finished: Page - 69 --> scraped\n",
      "- Finished: Page - 70 --> scraped\n",
      "- Finished: Page - 71 --> scraped\n",
      "- Finished: Page - 72 --> scraped\n",
      "- Finished: Page - 73 --> scraped\n",
      "- Finished: Page - 74 --> scraped\n",
      "- Finished: Page - 75 --> scraped\n",
      "- Finished: Page - 76 --> scraped\n",
      "- Finished: Page - 77 --> scraped\n",
      "- Finished: Page - 78 --> scraped\n",
      "- Finished: Page - 79 --> scraped\n",
      "- Finished: Page - 80 --> scraped\n",
      "- Finished: Page - 81 --> scraped\n",
      "- Finished: Page - 82 --> scraped\n",
      "- Finished: Page - 83 --> scraped\n",
      "- Finished: Page - 84 --> scraped\n",
      "- Finished: Page - 85 --> scraped\n",
      "- Finished: Page - 86 --> scraped\n",
      "- Finished: Page - 87 --> scraped\n",
      "- Finished: Page - 88 --> scraped\n",
      "- Finished: Page - 89 --> scraped\n"
     ]
    }
   ],
   "source": [
    "input_page = int(input('How many pages should we scraped?: '))\n",
    "sleep(2)\n",
    "\n",
    "URLs_all_page = GetURL()\n",
    "print('- Finished: Page - 1 --> scraped')\n",
    "\n",
    "for page in range(input_page-1):\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "    sleep(3)\n",
    "    next_button = driver.find_element('class name','artdeco-pagination__button--next')\n",
    "    next_button.click()\n",
    "    sleep(3)\n",
    "\n",
    "    page_source = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    \n",
    "    URLs_one_page = GetURL()\n",
    "    URLs_all_page = URLs_all_page + URLs_one_page\n",
    "    sleep(3)\n",
    "\n",
    "    print('- Finished: Page - {} --> scraped'.format(page+2))\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae9ca7f",
   "metadata": {},
   "source": [
    "### Show informations about scraped profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98cf4d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Info: In total, 888 profiles were scraped and recorded\n",
      "- Info: (888/888 sonuÃ§)\n",
      "- Info: \"ScrapedURLs.txt\" created and profiles are saved!\n"
     ]
    }
   ],
   "source": [
    "print('')\n",
    "sleep(3)\n",
    "print('- Info: In total, {} profiles were scraped and recorded'.format(len(URLs_all_page)))\n",
    "print('- Info: ({}'.format(len(URLs_all_page)) + '/' + result_number + ')')\n",
    "\n",
    "# Save scraped profiles into local file for backup\n",
    "with open(r'ScrapedURLs.txt', 'w') as fp:\n",
    "    for URL in URLs_all_page:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % URL)\n",
    "    print('- Info: \"ScrapedURLs.txt\" created and profiles are saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
